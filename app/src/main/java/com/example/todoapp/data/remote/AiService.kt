package com.example.todoapp.data.remote

/**
 * DISABLED: Cloud-based AI service removed.
 * Using on-device LLM via llama.cpp instead.
 * See: com.example.todoapp.llm.LocalAssistantRepository
 */

/*
import com.example.todoapp.data.model.GeminiRequest
import com.example.todoapp.data.model.GeminiResponse
import retrofit2.http.Body
import retrofit2.http.POST
import retrofit2.http.Query

interface AiService {
    @POST("v1beta/models/gemini-1.5-flash:generateContent")
    suspend fun sendChat(
        @Query("key") apiKey: String,
        @Body request: GeminiRequest
    ): GeminiResponse
}
*/
